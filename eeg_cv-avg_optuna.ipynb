{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.scheduler import CosineLRScheduler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.signal import resample, butter, filtfilt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from termcolor import cprint\n",
    "from sklearn.model_selection import KFold\n",
    "import datetime\n",
    "import os\n",
    "import pytz\n",
    "import gc\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from src.preprocess import CosineScheduler\n",
    "from src.preprocess import EarlyStopping\n",
    "# from src.models import EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EEGNetクラスの定義\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_channels, samples):\n",
    "        super(EEGNet, self).__init__()\n",
    "\n",
    "        self.firstconv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, (1, 51), stride=(1, 1), padding=(0, 25), bias=False),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, (num_channels, 1), stride=(1, 1), groups=16, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 4), stride=(1, 4)),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        self.separableConv = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, (1, 15), stride=(1, 1), padding=(0, 7), bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 8), stride=(1, 8)),\n",
    "            nn.Dropout(0.25)\n",
    "        )\n",
    "\n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(32 * (samples // 32), num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.firstconv(x)\n",
    "        x = self.depthwiseConv(x)\n",
    "        x = self.separableConv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classify(x)\n",
    "        return x\n",
    "\n",
    "# データの前処理関数\n",
    "def resample_data(data, target_rate, current_rate):\n",
    "    num_samples = int(data.shape[2] * target_rate / current_rate)\n",
    "    resampled_data = resample(data, num_samples, axis=2)\n",
    "    return resampled_data\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    b, a = butter(order, [lowcut / (0.5 * fs), highcut / (0.5 * fs)], btype='band', output='ba')\n",
    "    return b.astype(np.float32), a.astype(np.float32)  # 精度をfloat32に変更\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    filtered_data = filtfilt(b, a, data.astype(np.float32), axis=2)  # 精度をfloat32に変更\n",
    "    return filtered_data\n",
    "\n",
    "def standardize(data):\n",
    "    mean = np.mean(data, axis=2, keepdims=True)\n",
    "    std = np.std(data, axis=2, keepdims=True)\n",
    "    standardized_data = (data - mean) / std\n",
    "    return standardized_data\n",
    "\n",
    "def preprocess_eeg_data(data, target_rate, current_rate, lowcut, highcut, fs):\n",
    "    print(\"resample_data\")\n",
    "    data = resample_data(data, target_rate, current_rate)\n",
    "    gc.collect()\n",
    "    print(\"bandpass_filter\")\n",
    "    data = bandpass_filter(data, lowcut, highcut, fs)\n",
    "    gc.collect()\n",
    "    print(\"standardize\")\n",
    "    data = standardize(data)\n",
    "    return data\n",
    "\n",
    "def set_lr(lr, optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "# cosine scheduler\n",
    "class CosineScheduler:\n",
    "    def __init__(self, epochs, lr, warmup_length=5):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        epochs : int\n",
    "            学習のエポック数．\n",
    "        lr : float\n",
    "            学習率．\n",
    "        warmup_length : int\n",
    "            warmupを適用するエポック数．\n",
    "        \"\"\"\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.warmup = warmup_length\n",
    "\n",
    "    def __call__(self, epoch):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        epoch : int\n",
    "            現在のエポック数．\n",
    "        \"\"\"\n",
    "        progress = (epoch - self.warmup) / (self.epochs - self.warmup)\n",
    "        progress = np.clip(progress, 0.0, 1.0)\n",
    "        lr = self.lr * 0.5 * (1. + np.cos(np.pi * progress))\n",
    "\n",
    "        if self.warmup:\n",
    "            lr = lr * min(1., (epoch+1) / self.warmup)\n",
    "\n",
    "        return lr\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_acc_max = np.NINF\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_acc, model):\n",
    "\n",
    "        score = val_acc\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_acc, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation accuracy increased ({self.val_acc_max:.6f} --> {val_acc:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_acc_max = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# dataset_filename = \"train_val-1000.pt\"\n",
    "dataset_filename = \"train_val.pt\"\n",
    "dataset_filename = \"train_X.pt\"\n",
    "# dataset_filename = \"combined.pt\"\n",
    "folder_path = 'data/'\n",
    "# folder_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_in_batches(X, batch_size, preprocess_function, *args):\n",
    "#     num_samples = X.shape[0]\n",
    "#     for start_idx in range(0, num_samples, batch_size):\n",
    "#         end_idx = min(start_idx + batch_size, num_samples)\n",
    "#         yield preprocess_function(X[start_idx:end_idx], *args), start_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import datetime\n",
    "# import pytz\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from scipy.signal import resample, butter, filtfilt\n",
    "\n",
    "# # 上記で提供された前処理関数をここに挿入\n",
    "\n",
    "# def process_in_batches(X, batch_size, preprocess_function, *args):\n",
    "#     num_samples = X.shape[0]\n",
    "#     for start_idx in range(0, num_samples, batch_size):\n",
    "#         end_idx = min(start_idx + batch_size, num_samples)\n",
    "#         yield preprocess_function(X[start_idx:end_idx], *args), start_idx, end_idx\n",
    "\n",
    "# # ベースとなるフォルダ名\n",
    "# base_folder_name = \"outputs\"\n",
    "\n",
    "# # 日本のタイムゾーンを取得\n",
    "# jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "# # 現在の日付と時間を取得（日本のローカルタイム）\n",
    "# now = datetime.datetime.now(jst)\n",
    "\n",
    "# # フォルダ名を生成（例：2023-06-20/23-59）\n",
    "# save_folder_name = os.path.join(base_folder_name, now.strftime(\"%Y-%m-%d/%H-%M\"))\n",
    "\n",
    "# # フォルダを作成（存在しない場合）\n",
    "# os.makedirs(save_folder_name, exist_ok=True)\n",
    "\n",
    "# # 元データを読み出す\n",
    "# data = torch.load(folder_path + dataset_filename)\n",
    "# X, y = data\n",
    "\n",
    "# batch_size = 256  # メモリに収まるサイズに応じて調整\n",
    "# preprocessed_X = None\n",
    "\n",
    "# for preprocessed_batch, start_idx, end_idx in tqdm(process_in_batches(X.numpy(), batch_size, preprocess_eeg_data, target_rate, current_rate, lowcut, highcut, fs), desc=\"Preprocess\"):\n",
    "#     if preprocessed_X is None:\n",
    "#         preprocessed_X = preprocessed_batch\n",
    "#     else:\n",
    "#         preprocessed_X = np.concatenate([preprocessed_X, preprocessed_batch], axis=0)\n",
    "\n",
    "# # PyTorchテンソルに変換し、保存\n",
    "# X_tensor = torch.tensor(preprocessed_X, dtype=torch.float32).unsqueeze(1)  # (samples, 1, channels, timepoints)\n",
    "# y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# # 処理後のデータを保存\n",
    "# torch.save((X_tensor, y_tensor), os.path.join(save_folder_name, 'preprocessed_data.pt'))\n",
    "\n",
    "# print(X_tensor.shape)\n",
    "# print(y_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([82160, 1, 271, 128])\n",
    "torch.Size([82160])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ\n",
    "target_rate = 128\n",
    "num_channels = 271  # チャンネル数\n",
    "num_timepoints = target_rate  # タイムポイント数\n",
    "fs = 128\n",
    "current_rate = 281\n",
    "num_classes = 1854  # クラス数\n",
    "lr = 0.001\n",
    "num_epochs = 50\n",
    "batch_size=128\n",
    "n_splits = 5\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    print(\"Start objective\", trial.number)\n",
    "    \n",
    "\n",
    "    lowcut = trial.suggest_uniform('lowcut', 0.01, fs / 2 - 1)\n",
    "    highcut = trial.suggest_uniform('highcut', lowcut + 1, fs / 2)\n",
    "    \n",
    "    print(f\"lowcut: {lowcut}, highcut: {highcut}\")\n",
    "\n",
    "    # ベースとなるフォルダ名\n",
    "    base_folder_name = \"outputs\"\n",
    "\n",
    "    # 日本のタイムゾーンを取得\n",
    "    jst = pytz.timezone('Asia/Tokyo')\n",
    "\n",
    "    # 現在の日付と時間を取得（日本のローカルタイム）\n",
    "    now = datetime.datetime.now(jst)\n",
    "\n",
    "    # フォルダ名を生成（例：06-20/23-59）\n",
    "    save_folder_name = os.path.join(base_folder_name, now.strftime(\"%Y-%m-%d/%H-%M\"))\n",
    "\n",
    "    # フォルダを作成（存在しない場合）\n",
    "    os.makedirs(save_folder_name, exist_ok=True)\n",
    "\n",
    "    # 元データを読み出す\n",
    "    # data = torch.load(folder_path+dataset_filename)\n",
    "    # X, y = data\n",
    "    # del data\n",
    "\n",
    "    X = torch.load(os.path.join(folder_path, 'train_X.pt'))\n",
    "    y = torch.load(os.path.join(folder_path, 'train_y.pt'))\n",
    "\n",
    "    # 前処理を行うコード（ここに適切な前処理を行うコードを書く）\n",
    "    preprocessed_data = preprocess_eeg_data(X.numpy(), target_rate, current_rate, lowcut, highcut, fs)\n",
    "    del X\n",
    "\n",
    "    # PyTorchテンソルに変換\n",
    "    X = torch.tensor(preprocessed_data, dtype=torch.float32).unsqueeze(1)  # (samples, 1, channels, timepoints)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "\n",
    "    accuracy = Accuracy(\n",
    "        task=\"multiclass\", num_classes=num_classes, top_k=10\n",
    "    ).to(device)\n",
    "\n",
    "    max_val_acc = 0\n",
    "    max_val_acc_list = []\n",
    "\n",
    "\n",
    "    # KFoldによる交差検証の設定\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=3711)\n",
    "\n",
    "    # 交差検証のループ\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(dataset)):\n",
    "        print(f\"Fold {fold + 1}\")\n",
    "\n",
    "        # トレーニングデータと検証データに分割\n",
    "        train_data = torch.utils.data.Subset(dataset, train_index)\n",
    "        val_data = torch.utils.data.Subset(dataset, val_index)\n",
    "        print(train_data.dataset[0])\n",
    "\n",
    "        # データローダの定義\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # モデルの定義\n",
    "        model = EEGNet(num_classes=num_classes, num_channels=num_channels, samples=target_rate).to(device)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        # optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.02)\n",
    "        scheduler = CosineLRScheduler(optimizer, t_initial=100, lr_min=1e-6,\n",
    "                                    warmup_t=3, warmup_lr_init=1e-6, warmup_prefix=True)\n",
    "        early_stopping = EarlyStopping(patience=2, verbose=True)\n",
    "\n",
    "        max_val_acc = 0  # 各Foldの最大検証精度を追跡するために、ループの内部で初期化\n",
    "\n",
    "        # トレーニングループ\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "            train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "\n",
    "            model.train()\n",
    "            for X, y in tqdm(train_loader, desc=\"Train\"):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                y_pred = model(X)\n",
    "\n",
    "                loss = F.cross_entropy(y_pred, y)\n",
    "                train_loss.append(loss.item())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                acc = accuracy(y_pred, y)\n",
    "                train_acc.append(acc.item())\n",
    "\n",
    "            model.eval()\n",
    "            for X, y in tqdm(val_loader, desc=\"Validation\"):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    y_pred = model(X)\n",
    "\n",
    "                val_loss.append(F.cross_entropy(y_pred, y).item())\n",
    "                val_acc.append(accuracy(y_pred, y).item())\n",
    "\n",
    "            scheduler.step(np.mean(val_loss))  # 学習率を調整\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | train loss: {np.mean(train_loss):.3f} | train acc: {np.mean(train_acc):.3f} | val loss: {np.mean(val_loss):.3f} | val acc: {np.mean(val_acc):.3f}\")\n",
    "\n",
    "            # 各Foldの最初のエポックでモデルを保存\n",
    "            if epoch == 0:\n",
    "                torch.save(model.state_dict(), os.path.join(save_folder_name, f\"model_best_fold{fold+1}.pt\"))\n",
    "                print(f\"Initial model for Fold {fold+1} saved.\")\n",
    "\n",
    "            val_acc_mean = np.mean(val_acc)\n",
    "            if val_acc_mean > max_val_acc:\n",
    "                cprint(\"New best.\", \"cyan\")\n",
    "                # Fold番号をファイル名に含める\n",
    "                torch.save(model.state_dict(), os.path.join(save_folder_name, f\"model_best_fold{fold+1}.pt\"))\n",
    "                max_val_acc = np.mean(val_acc)\n",
    "\n",
    "\n",
    "            early_stopping(val_acc_mean, model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping. Max Acc = \", max_val_acc)\n",
    "                break\n",
    "        \n",
    "        max_val_acc_list.append(max_val_acc)\n",
    "        print(\"Max Acc = \", max_val_acc)\n",
    "\n",
    "    mean_acc = np.mean(max_val_acc_list)\n",
    "    print(\"Acc mean = \", mean_acc)\n",
    "\n",
    "    return mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-17 22:17:55,156] Using an existing study with name 'bandpass_filter_study_5cv' instead of creating a new one.\n",
      "C:\\Users\\tshigata\\AppData\\Local\\Temp\\ipykernel_17332\\2222125907.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  lowcut = trial.suggest_uniform('lowcut', 0.01, fs / 2 - 1)\n",
      "C:\\Users\\tshigata\\AppData\\Local\\Temp\\ipykernel_17332\\2222125907.py:9: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  highcut = trial.suggest_uniform('highcut', lowcut + 1, fs / 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start objective 3\n",
      "lowcut: 58.907602980607194, highcut: 62.28420506503475\n",
      "resample_data\n",
      "bandpass_filter\n",
      "standardize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\_methods.py:176: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "C:\\Users\\tshigata\\AppData\\Local\\Temp\\ipykernel_17332\\2222125907.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65728, 1, 271, 128])\n",
      "torch.Size([65728])\n",
      "Fold 1\n",
      "(tensor([[[0., -0., 0.,  ..., -0., -0., -0.],\n",
      "         [0., -0., 0.,  ..., -0., -0., -0.],\n",
      "         [0., -0., -0.,  ..., -0., -0., -0.],\n",
      "         ...,\n",
      "         [-0., 0., -0.,  ..., 0., 0., 0.],\n",
      "         [-0., 0., -0.,  ..., 0., 0., 0.],\n",
      "         [-0., 0., -0.,  ..., 0., 0., 0.]]]), tensor(1759))\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  72%|███████▏  | 295/411 [00:28<00:11, 10.41it/s]\n",
      "[W 2024-07-17 22:22:06,176] Trial 3 failed with parameters: {'lowcut': 58.907602980607194, 'highcut': 62.28420506503475} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Temp\\ipykernel_17332\\2222125907.py\", line 103, in objective\n",
      "    acc = accuracy(y_pred, y)\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\metric.py\", line 236, in forward\n",
      "    self._forward_cache = self._forward_reduce_state_update(*args, **kwargs)\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\metric.py\", line 302, in _forward_reduce_state_update\n",
      "    self.update(*args, **kwargs)\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\metric.py\", line 390, in wrapped_func\n",
      "    update(*args, **kwargs)\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\classification\\stat_scores.py\", line 315, in update\n",
      "    _multiclass_stat_scores_tensor_validation(\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py\", line 303, in _multiclass_stat_scores_tensor_validation\n",
      "    num_unique_values = len(torch.unique(target))\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_jit_internal.py\", line 497, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_jit_internal.py\", line 497, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\functional.py\", line 996, in _return_output\n",
      "    output, _, _ = _unique_impl(input, sorted, return_inverse, return_counts, dim)\n",
      "  File \"C:\\Users\\tshigata\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\functional.py\", line 910, in _unique_impl\n",
      "    output, inverse_indices, counts = torch._unique2(\n",
      "KeyboardInterrupt\n",
      "[W 2024-07-17 22:22:06,205] Trial 3 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[0;32m      2\u001b[0m     load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      3\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     storage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///db.sqlite3\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Specify the storage URL here.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbandpass_filter_study_5cv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# study.enqueue_trial({'lowcut': 0.5, 'highcut': 50.0}, user_attrs={\"memo\": \"baseline\"})\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# study.enqueue_trial({'lowcut': 0.1, 'highcut': 50.0}, user_attrs={\"memo\": \"baseline+\"})\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# study.enqueue_trial({'lowcut': 0.5, 'highcut': 60.0}, user_attrs={\"memo\": \"baseline+\"})\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# study.enqueue_trial({'lowcut': 0.01, 'highcut': 60.0}, user_attrs={\"memo\": \"no filter\"})\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# study.enqueue_trial({'lowcut': 0.01, 'highcut': 63.0}, user_attrs={\"memo\": \"no filter\"})\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(study\u001b[38;5;241m.\u001b[39mbest_trial)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[33], line 103\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    100\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    101\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 103\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     train_acc\u001b[38;5;241m.\u001b[39mappend(acc\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m    106\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\metric.py:236\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_reduce_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\metric.py:302\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    303\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    305\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\metric.py:390\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 390\u001b[0m         update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\classification\\stat_scores.py:315\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[1;32m--> 315\u001b[0m     \u001b[43m_multiclass_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[0;32m    319\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[0;32m    320\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[0;32m    321\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchmetrics\\functional\\classification\\stat_scores.py:303\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[1;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    299\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and `preds` should be (N, C, ...).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m     )\n\u001b[1;32m--> 303\u001b[0m num_unique_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     check \u001b[38;5;241m=\u001b[39m num_unique_values \u001b[38;5;241m>\u001b[39m num_classes\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_jit_internal.py:497\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_jit_internal.py:497\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\functional.py:996\u001b[0m, in \u001b[0;36m_return_output\u001b[1;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[1;32m--> 996\u001b[0m output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\functional.py:910\u001b[0m, in \u001b[0;36m_unique_impl\u001b[1;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[0;32m    902\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39munique_dim(\n\u001b[0;32m    903\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    904\u001b[0m         dim,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    907\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[0;32m    908\u001b[0m     )\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 910\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    load_if_exists=True,\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "    study_name=\"bandpass_filter_study_5cv\",\n",
    ")\n",
    "# study.enqueue_trial({'lowcut': 0.5, 'highcut': 50.0}, user_attrs={\"memo\": \"baseline\"})\n",
    "# study.enqueue_trial({'lowcut': 0.1, 'highcut': 50.0}, user_attrs={\"memo\": \"baseline+\"})\n",
    "# study.enqueue_trial({'lowcut': 0.5, 'highcut': 60.0}, user_attrs={\"memo\": \"baseline+\"})\n",
    "# study.enqueue_trial({'lowcut': 0.1, 'highcut': 60.0}, user_attrs={\"memo\": \"baseline+\"})\n",
    "# study.enqueue_trial({'lowcut': 0.5, 'highcut': 63.0}, user_attrs={\"memo\": \"no filter\"})\n",
    "# study.enqueue_trial({'lowcut': 0.01, 'highcut': 60.0}, user_attrs={\"memo\": \"no filter\"})\n",
    "# study.enqueue_trial({'lowcut': 0.01, 'highcut': 63.0}, user_attrs={\"memo\": \"no filter\"})\n",
    "study.optimize(objective, n_trials=200)\n",
    "print(study.best_trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
